"""
ComfyUIèŠ‚ç‚¹å®ç°
å®šä¹‰Flux-Kontextå›¾åƒç”ŸæˆèŠ‚ç‚¹
"""

import torch
import random
from typing import Any, Tuple, Optional, Dict
from concurrent.futures import ThreadPoolExecutor, as_completed
from .api_client import FluxKontextAPI, FluxKontextAPIError
from .config import default_config
from .utils import download_image, pil_to_tensor, tensor_to_base64, format_error_message

class FluxKontextNode:
    """Flux-Kontexté€šç”¨å›¾åƒç”ŸæˆèŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰èŠ‚ç‚¹è¾“å…¥ç±»å‹"""
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": ""}),
                "model": (["flux-kontext-pro", "flux-kontext-max"],),
                "num_images": ([1, 2, 4], {"default": 1}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "guidance_scale": ("FLOAT", {"default": 3.0, "min": 0.0, "max": 10.0, "step": 0.1}),
                "num_inference_steps": ("INT", {"default": 28, "min": 1, "max": 100}),
                "aspect_ratio": (default_config.SUPPORTED_ASPECT_RATIOS,),
                "output_format": (default_config.SUPPORTED_OUTPUT_FORMATS,),
                "safety_tolerance": ("INT", {"default": 2, "min": 0, "max": 6}),
                "prompt_upsampling": ("BOOLEAN", {"default": False}),
            },
            "optional": {
                "image": ("IMAGE",),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("image", "image_url", "status")
    FUNCTION = "execute"
    CATEGORY = "TuZi/Flux-Kontext"
    DESCRIPTION = "ä½¿ç”¨Flux-Kontext APIç”Ÿæˆé«˜è´¨é‡å›¾åƒ (é€šç”¨ç‰ˆ)"
    
    def _create_error_result(self, error_message: str, original_image: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """åˆ›å»ºä¸€ä¸ªåŒ…å«é”™è¯¯ä¿¡æ¯çš„æ ‡å‡†è¾“å‡ºï¼Œå¦‚æœå¯èƒ½åˆ™è¿”å›åŸå§‹å›¾åƒä»¥é¿å…å·¥ä½œæµä¸­æ–­"""
        print(f"èŠ‚ç‚¹æ‰§è¡Œé”™è¯¯: {error_message}")
        # å¦‚æœæœ‰åŸå§‹è¾“å…¥å›¾åƒï¼Œå°±è¿”å›å®ƒï¼Œå¦åˆ™è¿”å›ä¸€ä¸ªç©ºçš„é»‘è‰²å›¾åƒ
        if original_image is not None:
            image_out = original_image
        else:
            # åˆ›å»ºä¸€ä¸ª1x1çš„é»‘è‰²å›¾åƒä½œä¸ºå ä½ç¬¦
            image_out = torch.zeros((1, 1, 3), dtype=torch.uint8)
            
        return {
            "ui": {"string": [error_message]},
            "result": (image_out, "N/A", f"å¤±è´¥: {error_message}")
        }

    def execute(self, 
                prompt: str,
                model: str,
                num_images: int,
                seed: int,
                guidance_scale: float,
                num_inference_steps: int,
                aspect_ratio: str,
                output_format: str,
                safety_tolerance: int,
                prompt_upsampling: bool,
                image: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, str, str]:
        """
        èŠ‚ç‚¹æ‰§è¡Œæ–¹æ³•
        """
        api_key = default_config.get_api_key()
        if not api_key:
            return self._create_error_result(default_config.api_key_error_message, image)

        input_image_b64 = None
        status_mode = "æ–‡ç”Ÿå›¾"
        if image is not None:
            input_image_b64 = tensor_to_base64(image, output_format)
            status_mode = "å›¾ç”Ÿå›¾"

        # --- å¹¶å‘æ‰§è¡Œé€»è¾‘ ---
        results_pil = []
        result_urls = []
        errors = []

        def generate_single_image(current_seed):
            try:
                api_client = FluxKontextAPI(api_key=api_key)
                api_params = {
                    "prompt": prompt,
                    "model": model,
                    "input_image": input_image_b64,
                    "seed": current_seed,
                    "aspect_ratio": aspect_ratio,
                    "output_format": output_format,
                    "safety_tolerance": safety_tolerance,
                    "prompt_upsampling": prompt_upsampling,
                    "guidance_scale": guidance_scale,
                    "num_inference_steps": num_inference_steps
                }
                pil_image, url = api_client.generate_image(**api_params)
                return pil_image, url
            except Exception as e:
                return e

        with ThreadPoolExecutor(max_workers=min(num_images, 4)) as executor:
            # ä½¿ç”¨åˆå§‹ç§å­æˆ–ä¸ºæ¯æ¬¡è¿­ä»£ç”Ÿæˆæ–°ç§å­
            seeds = [seed + i if seed != 0 else random.randint(0, 0xffffffffffffffff) for i in range(num_images)]
            
            future_to_seed = {executor.submit(generate_single_image, s): s for s in seeds}
            
            for future in as_completed(future_to_seed):
                try:
                    result = future.result()
                    if isinstance(result, Exception):
                        errors.append(f"ç§å­ {future_to_seed[future]} æ‰§è¡Œå¤±è´¥: {result}")
                    else:
                        pil_img, url = result
                        results_pil.append(pil_img)
                        result_urls.append(url)
                except Exception as exc:
                    errors.append(f"ç§å­ {future_to_seed[future]} æ‰§è¡Œæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {exc}")

        if not results_pil:
            error_summary = "\n".join(errors)
            return self._create_error_result(f"æ‰€æœ‰å›¾åƒç”Ÿæˆå‡å¤±è´¥ã€‚\n{error_summary}", image)

        # --- å¤„ç†æˆåŠŸçš„ç»“æœ ---
        result_image_tensor = pil_to_tensor(results_pil)
        
        # å‡†å¤‡è¾“å‡ºä¿¡æ¯
        success_count = len(results_pil)
        final_status = f"æˆåŠŸ {success_count}/{num_images} å¼  | "
        if errors:
            final_status += f"å¤±è´¥ {len(errors)} å¼ : {'; '.join(errors)[:150]}..."
        
        final_urls = "\n".join(result_urls)
        
        return {
            "ui": {"string": [f"{final_status}\nURLs:\n{final_urls}"]},
            "result": (result_image_tensor, final_urls, final_status)
        }

# æ³¨å†ŒèŠ‚ç‚¹åˆ°ComfyUI
NODE_CLASS_MAPPINGS = {
    "FluxKontextNode": FluxKontextNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "FluxKontextNode": "ğŸ° Flux Kontext API"
} 